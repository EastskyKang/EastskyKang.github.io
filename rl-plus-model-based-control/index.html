<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion | DONGHO KANG</title> <meta name="author" content="Dongho Kang"/> <meta name="description" content="I am a doctoral student at ETH Zurich and a research assistant at Computational Robotics Lab. My research aims to create a legged robot that can perform natural, animal-like motion. Thus, my research interests are broad ranging to legged locomotion control, computational model of character animation and design optimization for robotics applications. "/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://donghok.me/rl-plus-model-based-control/"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <d-front-matter> <script async type="text/json">{
      "title": "RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion",
      "description": "",
      "published": "May 27, 2023",
      "authors": [
        {
          "author": "Dongho Kang",
          "authorURL": "https://donghok.me/",
          "affiliations": [
            {
              "name": "CRL<d-footnote>Computational Robotics Lab.</d-footnote>, ETH Zurich",
              "url": ""
            }
          ]
        },
        {
          "author": "Jin Cheng",
          "authorURL": "",
          "affiliations": [
            {
              "name": "CRL, ETH Zurich",
              "url": ""
            }
          ]
        },
        {
          "author": "Miguel Zamora",
          "authorURL": "",
          "affiliations": [
            {
              "name": "CRL, ETH Zurich",
              "url": ""
            }
          ]
        },
        {
          "author": "Fatemeh Zargarbashi",
          "authorURL": "",
          "affiliations": [
            {
              "name": "CRL, ETH Zurich",
              "url": ""
            }
          ]
        },
        {
          "author": "Stelian Coros",
          "authorURL": "http://crl.ethz.ch/",
          "affiliations": [
            {
              "name": "CRL, ETH Zurich",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://donghok.me/">DONGHO KANG</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/bio-inspired-robots/">student projects</a> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid" src="/assets/img/2023-05-28/kang2023rl.png" alt="" title="teaser"> </div> </div> <p> </p> <h1>Abstract</h1> <p> This letter presents a control framework that combines model-based optimal control and reinforcement learning (RL) to achieve versatile and robust legged locomotion. Our approach enhances the RL training process by incorporating on-demand reference motions generated through finite-horizon optimal control, covering a broad range of velocities and gaits. These reference motions serve as targets for the RL policy to imitate, resulting in the development of robust control policies that can be learned efficiently and reliably. Moreover, by considering whole-body dynamics, RL overcomes the inherent limitations of modelling simplifications. Through simulation and hardware experiments, we demonstrate the robustness and controllability of the RL training process within our framework. Furthermore, our method demonstrates the ability to generalize reference motions and handle more complex locomotion tasks that may pose challenges for the simplified model, leveraging the flexibility of RL. </p> <p> <b>Preprint: [<a href="/assets/pdf/kang2023rl.pdf">PDF</a>] / [<a href="https://arxiv.org/abs/2305.17842" target="_blank" rel="noopener noreferrer">ArXiv</a>]</b> </p> <hr> <h1>Supplementary Video</h1> <p> </p> <div class="embed-container"> <iframe src="https://www.youtube.com/embed/gXDP87yVq4o" width="700" height="480" frameborder="0" allowfullscreen=""> </iframe> </div> <hr> <h1>Demos</h1> <p> </p> <div class="embed-container"> <iframe src="https://www.youtube.com/embed/PCT5f6xsASk" width="700" height="480" frameborder="0" allowfullscreen=""> </iframe> </div> <hr> <h1>Bibtex</h1> <p> <figure class="highlight"><pre><code class="language-txt" data-lang="txt">@misc{kang2023rl,
  title={RL + Model-based Control: Using On-demand Optimal Control to Learn Versatile Legged Locomotion}, 
  author={Kang, Dongho and Cheng, Jin and Zamora, Miguel and Zargarbashi, Fatemeh and Coros, Stelian},
  year={2023},
  eprint={2305.17842},
  archivePrefix={arXiv},
  primaryClass={cs.RO}
}</code></pre></figure> </p> <hr> <h1>Acknowledgment</h1> <p> This work has received funding from the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme (grant agreement No. 866480.) </p> <p> We express our gratitude to Zijun Hui for his assistance with the robot experiments. </p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Dongho Kang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Last updated: July 06, 2023. </div> </footer> <d-bibliography src="/assets/bibliography/"></d-bibliography> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>